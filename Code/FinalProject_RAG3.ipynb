{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W3wGNXeo-Iah",
        "outputId": "2ce5f719-e33d-4d01-c67b-5255aca7ac78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.1/434.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.8/358.8 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m118.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m583.9/583.9 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.8/132.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.1/250.1 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.3/394.3 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.16 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.17-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.52 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.3.55)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (2.11.3)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.24.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (5.29.4)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (0.3.33)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (4.13.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (1.0.8)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (0.14.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (1.3.1)\n",
            "Downloading langchain_google_genai-2.1.3-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.17-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, google-ai-generativelanguage, langchain-google-genai\n",
            "Successfully installed filetype-1.2.0 google-ai-generativelanguage-0.6.17 langchain-google-genai-2.1.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "05bca7724bd640b2aa0a988c79835fb4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/302.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m297.0/302.3 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting playwright\n",
            "  Downloading playwright-1.51.0-py3-none-manylinux1_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting pyee<13,>=12 (from playwright)\n",
            "  Downloading pyee-12.1.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: greenlet<4.0.0,>=3.1.1 in /usr/local/lib/python3.11/dist-packages (from playwright) (3.2.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from pyee<13,>=12->playwright) (4.13.2)\n",
            "Downloading playwright-1.51.0-py3-none-manylinux1_x86_64.whl (45.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyee-12.1.1-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pyee, playwright\n",
            "Successfully installed playwright-1.51.0 pyee-12.1.1\n",
            "Downloading Chromium 134.0.6998.35 (playwright build v1161)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/chromium/1161/chromium-linux.zip\u001b[22m\n",
            "\u001b[1G164.9 MiB [] 0% 0.0s\u001b[0K\u001b[1G164.9 MiB [] 0% 53.2s\u001b[0K\u001b[1G164.9 MiB [] 0% 22.9s\u001b[0K\u001b[1G164.9 MiB [] 0% 12.7s\u001b[0K\u001b[1G164.9 MiB [] 0% 7.0s\u001b[0K\u001b[1G164.9 MiB [] 2% 3.8s\u001b[0K\u001b[1G164.9 MiB [] 3% 2.5s\u001b[0K\u001b[1G164.9 MiB [] 5% 2.1s\u001b[0K\u001b[1G164.9 MiB [] 6% 1.8s\u001b[0K\u001b[1G164.9 MiB [] 8% 1.6s\u001b[0K\u001b[1G164.9 MiB [] 10% 1.5s\u001b[0K\u001b[1G164.9 MiB [] 11% 1.3s\u001b[0K\u001b[1G164.9 MiB [] 13% 1.3s\u001b[0K\u001b[1G164.9 MiB [] 15% 1.2s\u001b[0K\u001b[1G164.9 MiB [] 16% 1.1s\u001b[0K\u001b[1G164.9 MiB [] 18% 1.1s\u001b[0K\u001b[1G164.9 MiB [] 20% 1.0s\u001b[0K\u001b[1G164.9 MiB [] 21% 1.0s\u001b[0K\u001b[1G164.9 MiB [] 23% 1.0s\u001b[0K\u001b[1G164.9 MiB [] 25% 0.9s\u001b[0K\u001b[1G164.9 MiB [] 26% 0.9s\u001b[0K\u001b[1G164.9 MiB [] 28% 0.9s\u001b[0K\u001b[1G164.9 MiB [] 30% 0.8s\u001b[0K\u001b[1G164.9 MiB [] 31% 0.8s\u001b[0K\u001b[1G164.9 MiB [] 33% 0.8s\u001b[0K\u001b[1G164.9 MiB [] 35% 0.7s\u001b[0K\u001b[1G164.9 MiB [] 36% 0.7s\u001b[0K\u001b[1G164.9 MiB [] 38% 0.7s\u001b[0K\u001b[1G164.9 MiB [] 40% 0.7s\u001b[0K\u001b[1G164.9 MiB [] 41% 0.7s\u001b[0K\u001b[1G164.9 MiB [] 43% 0.6s\u001b[0K\u001b[1G164.9 MiB [] 45% 0.6s\u001b[0K\u001b[1G164.9 MiB [] 46% 0.6s\u001b[0K\u001b[1G164.9 MiB [] 48% 0.6s\u001b[0K\u001b[1G164.9 MiB [] 50% 0.5s\u001b[0K\u001b[1G164.9 MiB [] 51% 0.5s\u001b[0K\u001b[1G164.9 MiB [] 53% 0.5s\u001b[0K\u001b[1G164.9 MiB [] 55% 0.5s\u001b[0K\u001b[1G164.9 MiB [] 56% 0.5s\u001b[0K\u001b[1G164.9 MiB [] 58% 0.4s\u001b[0K\u001b[1G164.9 MiB [] 60% 0.4s\u001b[0K\u001b[1G164.9 MiB [] 61% 0.4s\u001b[0K\u001b[1G164.9 MiB [] 63% 0.4s\u001b[0K\u001b[1G164.9 MiB [] 65% 0.4s\u001b[0K\u001b[1G164.9 MiB [] 66% 0.4s\u001b[0K\u001b[1G164.9 MiB [] 68% 0.3s\u001b[0K\u001b[1G164.9 MiB [] 70% 0.3s\u001b[0K\u001b[1G164.9 MiB [] 71% 0.3s\u001b[0K\u001b[1G164.9 MiB [] 73% 0.3s\u001b[0K\u001b[1G164.9 MiB [] 75% 0.3s\u001b[0K\u001b[1G164.9 MiB [] 76% 0.2s\u001b[0K\u001b[1G164.9 MiB [] 78% 0.2s\u001b[0K\u001b[1G164.9 MiB [] 79% 0.2s\u001b[0K\u001b[1G164.9 MiB [] 81% 0.2s\u001b[0K\u001b[1G164.9 MiB [] 83% 0.2s\u001b[0K\u001b[1G164.9 MiB [] 85% 0.2s\u001b[0K\u001b[1G164.9 MiB [] 86% 0.1s\u001b[0K\u001b[1G164.9 MiB [] 88% 0.1s\u001b[0K\u001b[1G164.9 MiB [] 90% 0.1s\u001b[0K\u001b[1G164.9 MiB [] 91% 0.1s\u001b[0K\u001b[1G164.9 MiB [] 93% 0.1s\u001b[0K\u001b[1G164.9 MiB [] 95% 0.1s\u001b[0K\u001b[1G164.9 MiB [] 96% 0.0s\u001b[0K\u001b[1G164.9 MiB [] 98% 0.0s\u001b[0K\u001b[1G164.9 MiB [] 99% 0.0s\u001b[0K\u001b[1G164.9 MiB [] 100% 0.0s\u001b[0K\n",
            "Chromium 134.0.6998.35 (playwright build v1161) downloaded to /root/.cache/ms-playwright/chromium-1161\n",
            "Downloading Chromium Headless Shell 134.0.6998.35 (playwright build v1161)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/chromium/1161/chromium-headless-shell-linux.zip\u001b[22m\n",
            "\u001b[1G100.9 MiB [] 0% 0.0s\u001b[0K\u001b[1G100.9 MiB [] 0% 31.0s\u001b[0K\u001b[1G100.9 MiB [] 0% 14.9s\u001b[0K\u001b[1G100.9 MiB [] 0% 12.4s\u001b[0K\u001b[1G100.9 MiB [] 1% 5.9s\u001b[0K\u001b[1G100.9 MiB [] 3% 3.1s\u001b[0K\u001b[1G100.9 MiB [] 5% 2.1s\u001b[0K\u001b[1G100.9 MiB [] 8% 1.4s\u001b[0K\u001b[1G100.9 MiB [] 10% 1.2s\u001b[0K\u001b[1G100.9 MiB [] 13% 1.0s\u001b[0K\u001b[1G100.9 MiB [] 15% 0.9s\u001b[0K\u001b[1G100.9 MiB [] 17% 0.9s\u001b[0K\u001b[1G100.9 MiB [] 19% 0.9s\u001b[0K\u001b[1G100.9 MiB [] 21% 0.8s\u001b[0K\u001b[1G100.9 MiB [] 25% 0.7s\u001b[0K\u001b[1G100.9 MiB [] 26% 0.7s\u001b[0K\u001b[1G100.9 MiB [] 30% 0.6s\u001b[0K\u001b[1G100.9 MiB [] 32% 0.6s\u001b[0K\u001b[1G100.9 MiB [] 34% 0.6s\u001b[0K\u001b[1G100.9 MiB [] 37% 0.5s\u001b[0K\u001b[1G100.9 MiB [] 40% 0.5s\u001b[0K\u001b[1G100.9 MiB [] 43% 0.6s\u001b[0K\u001b[1G100.9 MiB [] 45% 0.5s\u001b[0K\u001b[1G100.9 MiB [] 46% 0.5s\u001b[0K\u001b[1G100.9 MiB [] 48% 0.5s\u001b[0K\u001b[1G100.9 MiB [] 52% 0.4s\u001b[0K\u001b[1G100.9 MiB [] 54% 0.4s\u001b[0K\u001b[1G100.9 MiB [] 57% 0.4s\u001b[0K\u001b[1G100.9 MiB [] 60% 0.4s\u001b[0K\u001b[1G100.9 MiB [] 62% 0.3s\u001b[0K\u001b[1G100.9 MiB [] 66% 0.3s\u001b[0K\u001b[1G100.9 MiB [] 67% 0.3s\u001b[0K\u001b[1G100.9 MiB [] 72% 0.2s\u001b[0K\u001b[1G100.9 MiB [] 74% 0.2s\u001b[0K\u001b[1G100.9 MiB [] 77% 0.2s\u001b[0K\u001b[1G100.9 MiB [] 78% 0.2s\u001b[0K\u001b[1G100.9 MiB [] 81% 0.2s\u001b[0K\u001b[1G100.9 MiB [] 83% 0.1s\u001b[0K\u001b[1G100.9 MiB [] 87% 0.1s\u001b[0K\u001b[1G100.9 MiB [] 90% 0.1s\u001b[0K\u001b[1G100.9 MiB [] 94% 0.0s\u001b[0K\u001b[1G100.9 MiB [] 96% 0.0s\u001b[0K\u001b[1G100.9 MiB [] 100% 0.0s\u001b[0K\n",
            "Chromium Headless Shell 134.0.6998.35 (playwright build v1161) downloaded to /root/.cache/ms-playwright/chromium_headless_shell-1161\n",
            "Downloading Firefox 135.0 (playwright build v1475)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/firefox/1475/firefox-ubuntu-22.04.zip\u001b[22m\n",
            "\u001b[1G90.6 MiB [] 0% 0.0s\u001b[0K\u001b[1G90.6 MiB [] 0% 27.8s\u001b[0K\u001b[1G90.6 MiB [] 0% 13.4s\u001b[0K\u001b[1G90.6 MiB [] 0% 8.2s\u001b[0K\u001b[1G90.6 MiB [] 1% 5.0s\u001b[0K\u001b[1G90.6 MiB [] 3% 2.3s\u001b[0K\u001b[1G90.6 MiB [] 6% 1.5s\u001b[0K\u001b[1G90.6 MiB [] 9% 1.1s\u001b[0K\u001b[1G90.6 MiB [] 11% 1.0s\u001b[0K\u001b[1G90.6 MiB [] 15% 0.8s\u001b[0K\u001b[1G90.6 MiB [] 19% 0.7s\u001b[0K\u001b[1G90.6 MiB [] 23% 0.6s\u001b[0K\u001b[1G90.6 MiB [] 25% 0.6s\u001b[0K\u001b[1G90.6 MiB [] 28% 0.5s\u001b[0K\u001b[1G90.6 MiB [] 30% 0.5s\u001b[0K\u001b[1G90.6 MiB [] 35% 0.5s\u001b[0K\u001b[1G90.6 MiB [] 39% 0.4s\u001b[0K\u001b[1G90.6 MiB [] 41% 0.4s\u001b[0K\u001b[1G90.6 MiB [] 45% 0.4s\u001b[0K\u001b[1G90.6 MiB [] 47% 0.3s\u001b[0K\u001b[1G90.6 MiB [] 52% 0.3s\u001b[0K\u001b[1G90.6 MiB [] 56% 0.3s\u001b[0K\u001b[1G90.6 MiB [] 60% 0.2s\u001b[0K\u001b[1G90.6 MiB [] 63% 0.2s\u001b[0K\u001b[1G90.6 MiB [] 65% 0.2s\u001b[0K\u001b[1G90.6 MiB [] 69% 0.2s\u001b[0K\u001b[1G90.6 MiB [] 74% 0.1s\u001b[0K\u001b[1G90.6 MiB [] 79% 0.1s\u001b[0K\u001b[1G90.6 MiB [] 80% 0.1s\u001b[0K\u001b[1G90.6 MiB [] 85% 0.1s\u001b[0K\u001b[1G90.6 MiB [] 89% 0.1s\u001b[0K\u001b[1G90.6 MiB [] 93% 0.0s\u001b[0K\u001b[1G90.6 MiB [] 97% 0.0s\u001b[0K\u001b[1G90.6 MiB [] 100% 0.0s\u001b[0K\n",
            "Firefox 135.0 (playwright build v1475) downloaded to /root/.cache/ms-playwright/firefox-1475\n",
            "Downloading Webkit 18.4 (playwright build v2140)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/webkit/2140/webkit-ubuntu-22.04.zip\u001b[22m\n",
            "\u001b[1G92.3 MiB [] 0% 0.0s\u001b[0K\u001b[1G92.3 MiB [] 0% 28.4s\u001b[0K\u001b[1G92.3 MiB [] 0% 12.5s\u001b[0K\u001b[1G92.3 MiB [] 0% 7.8s\u001b[0K\u001b[1G92.3 MiB [] 1% 4.1s\u001b[0K\u001b[1G92.3 MiB [] 3% 2.1s\u001b[0K\u001b[1G92.3 MiB [] 6% 1.5s\u001b[0K\u001b[1G92.3 MiB [] 9% 1.1s\u001b[0K\u001b[1G92.3 MiB [] 11% 1.0s\u001b[0K\u001b[1G92.3 MiB [] 15% 0.8s\u001b[0K\u001b[1G92.3 MiB [] 17% 0.8s\u001b[0K\u001b[1G92.3 MiB [] 19% 0.8s\u001b[0K\u001b[1G92.3 MiB [] 23% 0.6s\u001b[0K\u001b[1G92.3 MiB [] 25% 0.6s\u001b[0K\u001b[1G92.3 MiB [] 28% 0.6s\u001b[0K\u001b[1G92.3 MiB [] 31% 0.5s\u001b[0K\u001b[1G92.3 MiB [] 35% 0.5s\u001b[0K\u001b[1G92.3 MiB [] 36% 0.5s\u001b[0K\u001b[1G92.3 MiB [] 40% 0.4s\u001b[0K\u001b[1G92.3 MiB [] 43% 0.4s\u001b[0K\u001b[1G92.3 MiB [] 47% 0.4s\u001b[0K\u001b[1G92.3 MiB [] 49% 0.4s\u001b[0K\u001b[1G92.3 MiB [] 52% 0.3s\u001b[0K\u001b[1G92.3 MiB [] 56% 0.3s\u001b[0K\u001b[1G92.3 MiB [] 57% 0.3s\u001b[0K\u001b[1G92.3 MiB [] 61% 0.3s\u001b[0K\u001b[1G92.3 MiB [] 63% 0.2s\u001b[0K\u001b[1G92.3 MiB [] 68% 0.2s\u001b[0K\u001b[1G92.3 MiB [] 69% 0.2s\u001b[0K\u001b[1G92.3 MiB [] 74% 0.2s\u001b[0K\u001b[1G92.3 MiB [] 76% 0.2s\u001b[0K\u001b[1G92.3 MiB [] 78% 0.1s\u001b[0K\u001b[1G92.3 MiB [] 80% 0.1s\u001b[0K\u001b[1G92.3 MiB [] 84% 0.1s\u001b[0K\u001b[1G92.3 MiB [] 88% 0.1s\u001b[0K\u001b[1G92.3 MiB [] 90% 0.1s\u001b[0K\u001b[1G92.3 MiB [] 94% 0.0s\u001b[0K\u001b[1G92.3 MiB [] 95% 0.0s\u001b[0K\u001b[1G92.3 MiB [] 100% 0.0s\u001b[0K\n",
            "Webkit 18.4 (playwright build v2140) downloaded to /root/.cache/ms-playwright/webkit-2140\n",
            "Downloading FFMPEG playwright build v1011\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/ffmpeg/1011/ffmpeg-linux.zip\u001b[22m\n",
            "\u001b[1G2.3 MiB [] 0% 0.0s\u001b[0K\u001b[1G2.3 MiB [] 2% 0.7s\u001b[0K\u001b[1G2.3 MiB [] 12% 0.2s\u001b[0K\u001b[1G2.3 MiB [] 31% 0.1s\u001b[0K\u001b[1G2.3 MiB [] 77% 0.0s\u001b[0K\u001b[1G2.3 MiB [] 100% 0.0s\u001b[0K\n",
            "FFMPEG playwright build v1011 downloaded to /root/.cache/ms-playwright/ffmpeg-1011\n",
            "Playwright Host validation warning: \n",
            "╔══════════════════════════════════════════════════════╗\n",
            "║ Host system is missing dependencies to run browsers. ║\n",
            "║ Missing libraries:                                   ║\n",
            "║     libwoff2dec.so.1.0.2                             ║\n",
            "║     libgstgl-1.0.so.0                                ║\n",
            "║     libgstcodecparsers-1.0.so.0                      ║\n",
            "║     libavif.so.13                                    ║\n",
            "║     libharfbuzz-icu.so.0                             ║\n",
            "║     libenchant-2.so.2                                ║\n",
            "║     libsecret-1.so.0                                 ║\n",
            "║     libhyphen.so.0                                   ║\n",
            "║     libmanette-0.2.so.0                              ║\n",
            "╚══════════════════════════════════════════════════════╝\n",
            "    at validateDependenciesLinux (/usr/local/lib/python3.11/dist-packages/playwright/driver/package/lib/server/registry/dependencies.js:216:9)\n",
            "\u001b[90m    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\u001b[39m\n",
            "    at async Registry._validateHostRequirements (/usr/local/lib/python3.11/dist-packages/playwright/driver/package/lib/server/registry/index.js:859:52)\n",
            "    at async Registry._validateHostRequirementsForExecutableIfNeeded (/usr/local/lib/python3.11/dist-packages/playwright/driver/package/lib/server/registry/index.js:957:7)\n",
            "    at async Registry.validateHostRequirementsForExecutablesIfNeeded (/usr/local/lib/python3.11/dist-packages/playwright/driver/package/lib/server/registry/index.js:946:43)\n",
            "    at async t.<anonymous> (/usr/local/lib/python3.11/dist-packages/playwright/driver/package/lib/cli/program.js:122:7)\n"
          ]
        }
      ],
      "source": [
        "#@title Install Requirements\n",
        "!pip install -qU \"langchain[google-vertexai]\"\n",
        "!pip install -qU langchain-google-vertexai\n",
        "!pip install langchain-google-genai\n",
        "!pip install -qU langchain-core\n",
        "!pip install -qU pypdf langchain_community\n",
        "!pip install playwright\n",
        "!playwright install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5bgLwiDn-Iai",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "383fb335-7e04-4a43-cdf9-77ca4dda839a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Google AI API key: ··········\n"
          ]
        }
      ],
      "source": [
        "#@title Get Google AI API Key\n",
        "## You need to put your Google AI API key.\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RQt_YQ6a-Iaj"
      },
      "outputs": [],
      "source": [
        "#@title Authenticate with Google Cloud and your project ID\n",
        "# Please put your google cloud project id.\n",
        "\n",
        "import vertexai\n",
        "from google.colab import auth\n",
        "\n",
        "gcp_project_id = 'tactical-attic-457605-s0' # @param {type: \"string\"}\n",
        "\n",
        "auth.authenticate_user(project_id=gcp_project_id)\n",
        "\n",
        "vertexai.init(project=gcp_project_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gA3EbPKZkg7",
        "outputId": "be379a1a-f8c5-44c6-f0ae-0bb07e5f35da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I recommend \"Les Bleus - Une autre histoire de France, 1996-2016.\"\n",
            "\n",
            "This 2016 French sports documentary, with a runtime of 103 minutes, charts 20 years of the French national soccer team, Les Bleus, whose ups and downs have mirrored those of French society. Pascal Blanchard, Sonia Dauger, and David Dietz directed it. It was added to Netflix on March 15th, 2017, and is rated TV-MA.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#@title RAG Train Model\n",
        "#!pip install -qU \"langchain[google-vertexai]\"\n",
        "#!pip install -qU langchain-google-vertexai\n",
        "#!pip install langchain-google-genai\n",
        "#!pip install -qU langchain-core\n",
        "#!pip install -qU pypdf langchain_community\n",
        "#!pip install playwright\n",
        "#!playwright install\n",
        "\"\"\"\n",
        "import requests\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_community.document_loaders import AsyncChromiumLoader\n",
        "from langchain_community.document_transformers import BeautifulSoupTransformer\n",
        "\n",
        "# embed the document\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_google_vertexai import VertexAIEmbeddings\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "import urllib.request\n",
        "\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "file_path = \"./movies_data_1.txt\"\n",
        "loader = TextLoader(file_path)\n",
        "\n",
        "docs = loader.load()\n",
        "\n",
        "\n",
        "# Split the text into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(docs)\n",
        "\n",
        "# load chat model\n",
        "llm = init_chat_model(\"gemini-2.0-flash-001\", model_provider=\"google_vertexai\")\n",
        "\n",
        "# load embedding model\n",
        "embedding_model = VertexAIEmbeddings(model=\"text-embedding-004\")\n",
        "\n",
        "# vector store\n",
        "vector_store = InMemoryVectorStore(embedding=embedding_model)\n",
        "vector_store.add_texts([docs.page_content for docs in splits])\n",
        "retriever = vector_store.as_retriever()\n",
        "\n",
        "\n",
        "# run inference with RAG\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "\n",
        "system_prompt = (\n",
        "    \"You are an LLM that should answer my questions with correct answers.\"\n",
        "    \"Please use the provided information to answer the question to the best \"\n",
        "    \"of your ability. If you are unsure how to answer the question, say that \"\n",
        "    \"you are unable to answer the question.\\n\"\n",
        "    \"{context}\"\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
        "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
        "\n",
        "results = rag_chain.invoke({\"input\": \"Can you give me a recommendation for a Netflix Movie that is a French Sports Movie? Can you then tell me more about that movie?\"})\n",
        "print(results['answer'])\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRFp7OL7R2EO",
        "outputId": "760b7330-8446-4d49-8e92-28f63991ecff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are a couple of suggestions of movies on Netflix that star Hugh Jackman:\n",
            "\n",
            "1.  **Real Steel**\n",
            "    *   Genre(s): Action & Adventure, Sci-Fi & Fantasy, Sports Movies\n",
            "    *   Audience Rating on IMDB: nan\n",
            "\n",
            "2.  **Les Misérables**\n",
            "    *   Genre(s): Dramas, International Movies, Music & Musicals\n",
            "    *   Audience Rating on IMDB: nan\n"
          ]
        }
      ],
      "source": [
        "\n",
        "results = rag_chain.invoke({\"input\": \"I want to watch a movie on Netflix with Hugh Jackman, can I have a couple of suggestions and their IMDB ratings (if available)?\"})\n",
        "print(results['answer'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGNvqXboSgd_",
        "outputId": "f200a7da-3369-4639-d19b-766d7437d69f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I recommend \"The Time Traveler's Wife\". It is a PG-13, Sci-Fi & Fantasy, Romantic movie about a librarian with a genetic disorder that causes him to involuntarily travel through time, appearing at various moments in the life of his true love. It stars Rachel McAdams and Eric Bana.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#results = rag_chain.invoke({\"input\": \"Can you give me a recommendation for a Netflix romance movie with time travel?\"})\n",
        "#print(results['answer'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgnL44dQViuH",
        "outputId": "25b3a37f-ca70-4065-9cf7-00c7d7e26197"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLACKPINK: Light Up the Sky has an IMDB rating of 8.4.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#results = rag_chain.invoke({\"input\": \"Can you give me a recommendation for a Netflix movie with an IMDB rating over 8?\"})\n",
        "#print(results['answer'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from langchain_core.documents import Document\n",
        "from langchain_community.document_loaders import CSVLoader, TextLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_google_vertexai import VertexAIEmbeddings\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "\n",
        "def load_and_normalize_data():\n",
        "    \"\"\"Load and normalize data from all sources with different schemas\"\"\"\n",
        "    all_docs = []\n",
        "\n",
        "    rt_files = [\n",
        "        \"netflix_movies_1_to_25.csv\",\n",
        "        \"netflix_movies_26_to_50.csv\",\n",
        "        \"netflix_movies_51_to_75.csv\",\n",
        "        \"netflix_movies_76_to_100.csv\"\n",
        "    ]\n",
        "\n",
        "    oscars_df = pd.read_csv(\"./the_oscar_award.csv\")\n",
        "    for _, row in oscars_df.iterrows():\n",
        "        content = (\n",
        "            f\"Oscar Nomination: {row['name']} in {row['category']} for {row['film']}\\n\"\n",
        "            f\"Year: {row['year_film']} (Ceremony: {row['year_ceremony']})\\n\"\n",
        "            f\"Winner: {'Yes' if row['winner'] else 'No'}\\n\"\n",
        "            f\"Ceremony Number: {row['ceremony']}\"\n",
        "        )\n",
        "        metadata = {\n",
        "            \"source\": \"oscars\",\n",
        "            \"year\": row['year_film'],\n",
        "            \"type\": \"award_nomination\",\n",
        "            \"title\": row['film'],\n",
        "            \"person\": row['name']\n",
        "        }\n",
        "        all_docs.append(Document(page_content=content, metadata=metadata))\n",
        "\n",
        "    imdb_df = pd.read_csv(\"./movies_with_ratings.csv\")\n",
        "    for _, row in imdb_df.iterrows():\n",
        "        genres = row['genres'] if pd.notna(row['genres']) else \"Unknown\"\n",
        "        content = (\n",
        "            f\"IMDB Entry: {row['primaryTitle']} ({row['originalTitle']})\\n\"\n",
        "            f\"Year: {row['startYear']}\\n\"\n",
        "            f\"Genres: {genres}\\n\"\n",
        "            f\"Rating: {row['averageRating']} ({row['numVotes']} votes)\"\n",
        "        )\n",
        "        metadata = {\n",
        "            \"source\": \"imdb\",\n",
        "            \"year\": row['startYear'],\n",
        "            \"type\": \"movie\",\n",
        "            \"title\": row['primaryTitle'],\n",
        "            \"original_title\": row['originalTitle'],\n",
        "            \"genres\": genres\n",
        "        }\n",
        "        all_docs.append(Document(page_content=content, metadata=metadata))\n",
        "\n",
        "\n",
        "    for rt_file in rt_files:\n",
        "        try:\n",
        "            rt_df = pd.read_csv(rt_file)\n",
        "            print(f\"Loaded {rt_file} successfully\")\n",
        "\n",
        "            for _, row in rt_df.iterrows():\n",
        "                content = (\n",
        "                    f\"ROTTEN TOMATOES: {row['Title']} ({row['Year']})\\n\"\n",
        "                    f\"Tomatometer: {row['Tomatometer']}\\n\"\n",
        "                    f\"Consensus: {row['Critics Consensus']}\\n\"\n",
        "                    f\"Director: {row['Directed By']}\\n\"\n",
        "                    f\"Stars: {row['Starring']}\"\n",
        "                )\n",
        "                metadata = {\n",
        "                    \"source\": \"rotten_tomatoes\",\n",
        "                    \"year\": row['Year'],\n",
        "                    \"type\": \"review\",\n",
        "                    \"title\": row['Title'],\n",
        "                    \"rating\": row['Tomatometer'],\n",
        "                    \"director\": row['Directed By'],\n",
        "                    \"stars\": row['Starring']\n",
        "                }\n",
        "                all_docs.append(Document(page_content=content, metadata=metadata))\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Warning: {rt_file} not found - skipping\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {rt_file}: {str(e)}\")\n",
        "\n",
        "\n",
        "    try:\n",
        "        text_loader = TextLoader(\"./movies_data_1.txt\")\n",
        "        text_docs = text_loader.load()\n",
        "        all_docs.extend(text_docs)\n",
        "    except FileNotFoundError:\n",
        "        print(\"Note: movies_data_1.txt not found - proceeding with CSV data only\")\n",
        "\n",
        "    return all_docs\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hcs8zLV8yjGh",
        "outputId": "53a26721-3343-4610-cdbe-288b108fd72a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query: Find a French sports movie that won or was nominated for an Oscar\n",
            "Answer: Based on the provided data, I can identify several French sports movies, but I cannot confirm whether any of them were nominated for or won an Oscar. Here's what I can tell you:\n",
            "\n",
            "*   **Dernier stade (Dernier stade)**: Released in 1994, genres include Drama and Sport.\n",
            "*   **Le vainqueur (Le vainqueur)**: Released in 1932, genre is Sport.\n",
            "*   **The French (The French)**: Released in 1982, genres include Documentary and Sport.\n",
            "*   **Le Champion (Le Champion)**: Released in 2019, genres include Biography, Documentary, and Sport.\n",
            "*   **Air of Paris (L'air de Paris)**: Released in 1954, genres include Drama and Sport.\n",
            "\n",
            "To determine if any of these films received an Oscar nomination or win, I would need to cross-reference this list with a database of Academy Award nominations and winners.\n",
            "--------------------------------------------------\n",
            "\n",
            "Query: Recommend a high-rated sports film from before 1950\n",
            "Answer: Based on the provided data, I recommend \"While Thousands Cheer\" (1940). It has the highest rating (8.2) among the listed sports films released before 1950.\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Query: Compare the Oscar winners to IMDB ratings for boxing movies\n",
            "Answer: Okay, I can compare the IMDB ratings of boxing movies provided with information about Academy Award (Oscar) nominations. However, I need the Oscar nominations data to perform the comparison.  Based on the IMDB data you've given me, here's what I can tell you *before* incorporating Oscar data:\n",
            "\n",
            "We have several movies titled \"Boxer\" or \"The Boxer\" across different years.  Here's a summary of their IMDB ratings and genres, which are relevant to identifying boxing movies:\n",
            "\n",
            "*   **Boxer (2013):** Action, Biography, Documentary; Rating: 8.7 (16 votes)\n",
            "*   **The Boxer (1997):** Drama, Romance, Sport; Rating: 7.0 (23062 votes)\n",
            "*   **The Boxer (2009):** Action, Drama, Sport; Rating: 4.9 (604 votes)\n",
            "*   **Boxer (1984):** Action, Drama, Sport; Rating: 6.5 (202 votes)\n",
            "*   **Boxer (2015):** Action, Drama; Rating: 5.9 (20 votes)\n",
            "\n",
            "To provide a proper comparison, please provide the Oscar nominations data. I need to know which boxing movies were nominated for or won Oscars, including the year of the award. Once I have that, I can:\n",
            "\n",
            "1.  Identify which of these movies (if any) received Oscar nominations/wins.\n",
            "2.  Compare the IMDB ratings of Oscar-nominated/winning boxing movies to those that weren't nominated.\n",
            "3.  Analyze if there's a correlation between Oscar recognition and IMDB ratings for this set of movies.\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize models\n",
        "llm = init_chat_model(\"gemini-2.0-flash-001\", model_provider=\"google_vertexai\")\n",
        "embedding_model = VertexAIEmbeddings(model=\"text-embedding-004\")\n",
        "\n",
        "# Load and process data\n",
        "all_docs = load_and_normalize_data()\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(all_docs)\n",
        "\n",
        "# Create vector store\n",
        "vector_store = InMemoryVectorStore.from_documents(splits, embedding=embedding_model)\n",
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
        "\n",
        "system_prompt = \"\"\"You're a film expert combining data from:\n",
        "1. Academy Awards (Oscars) nominations\n",
        "2. IMDB movie listings\n",
        "3. Other movie databases\n",
        "\n",
        "Key field mappings:\n",
        "- Movie titles may appear in 'film' (Oscars) or 'primaryTitle' (IMDB)\n",
        "- Years may be in 'year_film' or 'startYear'\n",
        "- For sports movies, check both genre fields and plot descriptions\n",
        "\n",
        "Analyze all provided context to answer thoroughly. If unsure, say what you can confirm.\n",
        "\n",
        "Context:\n",
        "{context}\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", system_prompt),\n",
        "    (\"human\", \"{input}\")\n",
        "])\n",
        "\n",
        "chain = create_retrieval_chain(\n",
        "    retriever,\n",
        "    create_stuff_documents_chain(llm, prompt)\n",
        ")\n",
        "\n",
        "queries = [\n",
        "    \"Find a French sports movie that won or was nominated for an Oscar\",\n",
        "    \"Recommend a high-rated sports film from before 1950\",\n",
        "    \"Compare the Oscar winners to IMDB ratings for boxing movies\"\n",
        "]\n",
        "\n",
        "for query in queries:\n",
        "    print(f\"\\nQuery: {query}\")\n",
        "    result = chain.invoke({\"input\": query})\n",
        "    print(\"Answer:\", result['answer'])\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "0XFiofBAEr00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    result = chain.invoke({\"input\": \"Can you give me a recommendation for a Netflix romance movie with time travel?\"})\n",
        "    print(\"Answer:\", result['answer'])\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lesKNqMZ4psN",
        "outputId": "7aa29883-6c3b-4414-dd14-b143316a3e28"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: Based on the information provided, here are a few Netflix romance movies featuring time travel:\n",
            "\n",
            "*   **The Time Traveler's Wife (2009):** A librarian with a genetic disorder involuntarily time travels, impacting his relationship with his true love.\n",
            "*   **When We First Met (2018):** A man travels back in time to try and alter the night he was friend-zoned.\n",
            "*   **About Time (2013):** A man uses his family's time-traveling ability to win the woman of his dreams.\n",
            "*   **Kate & Leopold (2001):** A woman guides a time-traveling 19th-century nobleman through the 21st century.\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}