{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3djES7dYE1o",
        "outputId": "7f551b6b-5516-4437-d1cb-f7af27fbf19a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.11/dist-packages (2.1.3)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.16 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.6.17)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.52 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.3.55)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (2.11.3)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.24.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (5.29.4)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (0.3.31)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (4.13.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (1.0.8)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (0.14.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (1.3.1)\n",
            "Requirement already satisfied: playwright in /usr/local/lib/python3.11/dist-packages (1.51.0)\n",
            "Requirement already satisfied: pyee<13,>=12 in /usr/local/lib/python3.11/dist-packages (from playwright) (12.1.1)\n",
            "Requirement already satisfied: greenlet<4.0.0,>=3.1.1 in /usr/local/lib/python3.11/dist-packages (from playwright) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from pyee<13,>=12->playwright) (4.13.2)\n",
            "Playwright Host validation warning: \n",
            "╔══════════════════════════════════════════════════════╗\n",
            "║ Host system is missing dependencies to run browsers. ║\n",
            "║ Missing libraries:                                   ║\n",
            "║     libwoff2dec.so.1.0.2                             ║\n",
            "║     libgstgl-1.0.so.0                                ║\n",
            "║     libgstcodecparsers-1.0.so.0                      ║\n",
            "║     libavif.so.13                                    ║\n",
            "║     libharfbuzz-icu.so.0                             ║\n",
            "║     libenchant-2.so.2                                ║\n",
            "║     libsecret-1.so.0                                 ║\n",
            "║     libhyphen.so.0                                   ║\n",
            "║     libmanette-0.2.so.0                              ║\n",
            "╚══════════════════════════════════════════════════════╝\n",
            "    at validateDependenciesLinux (/usr/local/lib/python3.11/dist-packages/playwright/driver/package/lib/server/registry/dependencies.js:216:9)\n",
            "    at async Registry._validateHostRequirements (/usr/local/lib/python3.11/dist-packages/playwright/driver/package/lib/server/registry/index.js:859:52)\n",
            "    at async Registry._validateHostRequirementsForExecutableIfNeeded (/usr/local/lib/python3.11/dist-packages/playwright/driver/package/lib/server/registry/index.js:957:7)\n",
            "    at async Registry.validateHostRequirementsForExecutablesIfNeeded (/usr/local/lib/python3.11/dist-packages/playwright/driver/package/lib/server/registry/index.js:946:43)\n",
            "    at async t.<anonymous> (/usr/local/lib/python3.11/dist-packages/playwright/driver/package/lib/cli/program.js:122:7)\n"
          ]
        }
      ],
      "source": [
        "#@title Install Requirements\n",
        "!pip install -qU \"langchain[google-vertexai]\"\n",
        "!pip install -qU langchain-google-vertexai\n",
        "!pip install langchain-google-genai\n",
        "!pip install -qU langchain-core\n",
        "!pip install -qU pypdf langchain_community\n",
        "!pip install playwright\n",
        "!playwright install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gT56kLp2ZT7M",
        "outputId": "881bfcba-3630-4043-fcb8-56f9c76da1c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Google AI API key: ··········\n"
          ]
        }
      ],
      "source": [
        "#@title Get Google AI API Key\n",
        "## You need to put your Google AI API key.\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1CxUI0nZcuW"
      },
      "outputs": [],
      "source": [
        "#@title Authenticate with Google Cloud and your project ID\n",
        "# Please put your google cloud project id.\n",
        "\n",
        "import vertexai\n",
        "from google.colab import auth\n",
        "\n",
        "gcp_project_id = '' # @param {type: \"string\"}       ## PUT GOOGLE CLOUD ASSIGNMENT NAME HERE\n",
        "\n",
        "auth.authenticate_user(project_id=gcp_project_id)\n",
        "\n",
        "vertexai.init(project=gcp_project_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gA3EbPKZkg7",
        "outputId": "f9683593-f277-4951-bc6a-adf54498066c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of chunks to embed: 7275\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7275/7275 [00:00<00:00, 1542881.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Pre-RAG Output ---\n",
            "*Mr. Peabody & Sherman* has the following ratings:  *   **IMDb:** 6.8/10 *   **Rotten Tomatoes:** 79% *\n",
            "**Common Sense Media:** 3/5\n",
            "\n",
            "--- Post-RAG Output ---\n",
            "Mr. Peabody & Sherman has a Rotten Tomato Score of 81%. The audience rating on IMDB is 6.7. The age rating is\n",
            "PG.\n"
          ]
        }
      ],
      "source": [
        "#@title RAG Train Model\n",
        "#!pip install -qU \"langchain[google-vertexai]\"\n",
        "#!pip install -qU langchain-google-vertexai\n",
        "#!pip install langchain-google-genai\n",
        "#!pip install -qU langchain-core\n",
        "#!pip install -qU pypdf langchain_community\n",
        "#!pip install playwright\n",
        "#!playwright install\n",
        "\n",
        "import requests\n",
        "import textwrap\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_community.document_loaders import AsyncChromiumLoader\n",
        "from langchain_community.document_transformers import BeautifulSoupTransformer\n",
        "# embed the document\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_google_vertexai import VertexAIEmbeddings\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "from langchain_core.documents import Document\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "# Wrap in LangChain LLM\n",
        "from langchain_community.llms import HuggingFacePipeline as LC_HF_Pipeline\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "\n",
        "################################# PUT QUESTION HERE #######################################\n",
        "question = \"What is the rating for Mr. Peabody & Sherman?\"\n",
        "\n",
        "\n",
        "############################## FILES TO RAG TRAIN BELOW ###################################\n",
        "# 1: Load movies_data_1.txt file\n",
        "file_path = \"./movies_data_1.txt\"\n",
        "txt_loader = TextLoader(file_path)\n",
        "txt_doc_1 = txt_loader.load()\n",
        "\n",
        "# 2: Load netflix_2025_released_movies CSV file\n",
        "csv_2025_released_movies = pd.read_csv(\"./netflix_2025_released_movies.csv\")\n",
        "\n",
        "csv_doc_2 = []\n",
        "for _, row in csv_2025_released_movies.iterrows():\n",
        "    content = f\"Title: {row.get('Title', '')}\\nRelease Date: {row.get('Release Date', '')}\\nGenre: {row.get('genre', '')}\\nDirector(s): {row.get('Director(s)', '')}\\nCast Highlights: {row.get('Cast Highlights', '')}Description: {row.get('Description', '')}\\n\"\n",
        "    csv_doc_2.append(Document(page_content=content))\n",
        "\n",
        "# 3: Load netflix_2024 pdf\n",
        "pdf_path = \"./netflix_2024.pdf\"\n",
        "pdf_loader = PyPDFLoader(pdf_path)\n",
        "pdf_docs_3 = pdf_loader.load()\n",
        "\n",
        "# 4: Load april_2025_movies pdf\n",
        "pdf_path = \"./netflix_april_2025.pdf\"\n",
        "pdf_loader = PyPDFLoader(pdf_path)\n",
        "pdf_docs_4 = pdf_loader.load()\n",
        "\n",
        "# 5: Load march_2025_movies pdf\n",
        "pdf_path = \"./netflix_march_2025.pdf\"\n",
        "pdf_loader = PyPDFLoader(pdf_path)\n",
        "pdf_docs_5 = pdf_loader.load()\n",
        "\n",
        "# 6: Load netflix_movies_1_to_100 CSV file\n",
        "csv_movies_1_to_100 = pd.read_csv(\"./netflix_movies_1_to_100.csv\")\n",
        "\n",
        "csv_doc_6 = []\n",
        "for _, row in csv_movies_1_to_100.iterrows():\n",
        "    content = f\"Rank: {row.get('Rank', '')}\\nTitle: {row.get('Title', '')}\\nRelease Year: {row.get('Year', '')}\\nRotten Tomato Score (Rating): {row.get('Tomatometer', '')}\\nCritics Consensus: {row.get('Critics Consensus', '')}\\nSynopsis: {row.get('Synopsis', '')}\\nCast: {row.get('Starring', '')}\\nDirected By: {row.get('Directed By', '')}\\nAvailable on: {row.get('Streaming On', '')}\\n\"\n",
        "    csv_doc_6.append(Document(page_content=content))\n",
        "\n",
        "csv_movies_ratings = pd.read_csv(\"./custom (1).csv\")\n",
        "\n",
        "csv_doc_7 = []\n",
        "for _, row in csv_movies_ratings.iterrows():\n",
        "    content = f\"Title ID: {row.get('tconst', '')}\\nPrimary Title: {row.get('primaryTitle', '')}\\nOriginal Title: {row.get('originalTitle', '')}\\nRelease Year: {row.get('startYear', '')}\\nGenres: {row.get('genres', '')}\\nAverage Rating: {row.get('averageRating', '')}\\nNumber of Votes: {row.get('numVotes', '')}\\n\"\n",
        "    csv_doc_7.append(Document(page_content=content))\n",
        "\n",
        "csv_oscar_nominations = pd.read_csv(\"./custom_ocar (1).csv\") \n",
        "\n",
        "csv_doc_8 = []\n",
        "for _, row in csv_oscar_nominations.iterrows():\n",
        "    content = f\"Film Year: {row.get('year_film', '')}\\nCeremony Year: {row.get('year_ceremony', '')}\\nCeremony Number: {row.get('ceremony', '')}\\nCategory: {row.get('category', '')}\\nCanonical Category: {row.get('canon_category', '')}\\nNominee: {row.get('name', '')}\\nFilm: {row.get('film', '')}\\nWinner: {'Yes' if row.get('winner', False) else 'No'}\\n\"\n",
        "    csv_doc_8.append(Document(page_content=content))\n",
        "\n",
        "##############################################################################################\n",
        "\n",
        "# Combine all docs\n",
        "docs = txt_doc_1 + csv_doc_2 + pdf_docs_3 + pdf_docs_4 +pdf_docs_5 + csv_doc_6 + csv_doc_7 + csv_doc_8\n",
        "\n",
        "\n",
        "# Split the text into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(docs)\n",
        "\n",
        "\n",
        "# load chat model\n",
        "llm = init_chat_model(\"gemini-2.0-flash-001\", model_provider=\"google_vertexai\")\n",
        "\n",
        "\n",
        "# load embedding model\n",
        "embedding_model = VertexAIEmbeddings(model=\"text-embedding-004\")\n",
        "\n",
        "# vector store\n",
        "vector_store = InMemoryVectorStore(embedding=embedding_model)\n",
        "print(f\"Number of chunks to embed: {len(splits)}\")\n",
        "from tqdm import tqdm\n",
        "vector_store.add_texts([docs.page_content for docs in tqdm(splits)])\n",
        "#vector_store.add_texts([docs.page_content for docs in splits])\n",
        "retriever = vector_store.as_retriever()\n",
        "\n",
        "# Run without RAG\n",
        "baseline_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are an LLM that should answer questions to the best of your ability.\"),\n",
        "    (\"human\", \"{input}\"),\n",
        "])\n",
        "baseline_chain = baseline_prompt | llm\n",
        "\n",
        "baseline_response = baseline_chain.invoke({\"input\": question})\n",
        "\n",
        "print(\"\\n--- Pre-RAG Output ---\")\n",
        "print(textwrap.fill(baseline_response.content, width=110))\n",
        "\n",
        "\n",
        "\n",
        "# run inference with RAG\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "\n",
        "system_prompt = (\n",
        "    \"You are an LLM that should answer my questions with correct answers.\"\n",
        "    \"Please answer the quuestion to the best of your ability. Use both the context and your own knowledge \"\n",
        "    \"to answer the question as best you can.\\n\"\n",
        "    \"{context}\"\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
        "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
        "\n",
        "results = rag_chain.invoke({\"input\": question})\n",
        "output_text = results['answer']\n",
        "wrapped_text = textwrap.fill(output_text, width=110)\n",
        "print(\"\\n--- Post-RAG Output ---\")\n",
        "print(wrapped_text)\n",
        "\n",
        "#print(results['answer'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUQkB3wHTtYD",
        "outputId": "b561e212-dadd-45f5-d805-037f1c63b962"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Okay, here are the comedies with Adam Sandler that are available on Netflix, according to the information I have:\n",
            "\n",
            "*   **Sandy Wexler** (2017)\n",
            "*   **Adam Sandler: 100% Fresh** (2018)\n",
            "*   **Anger Management** (2003)\n",
            "\n",
            "I also found a listing for \"**ADAM SANDLER 100% FRESH**\" (2018) which appears to be the same as \"**Adam Sandler: 100% Fresh**\" (2018).\n"
          ]
        }
      ],
      "source": [
        "question = \"Help me find a comedy with Adam Sandler on Netflix\"\n",
        "results = rag_chain.invoke({\"input\": question})\n",
        "print(results['answer'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGNvqXboSgd_",
        "outputId": "bc9911fe-a910-4fa9-b555-4bda28f8da66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here is a list of Netflix romance movies with time travel:\n",
            "*   The Time Traveler's Wife\n",
            "*   About Time\n",
            "*   When We First Met\n",
            "*   Kate & Leopold\n"
          ]
        }
      ],
      "source": [
        "results = rag_chain.invoke({\"input\": \"Can you give me a list of Netflix romance movies with time travel?\"})\n",
        "print(results['answer'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
